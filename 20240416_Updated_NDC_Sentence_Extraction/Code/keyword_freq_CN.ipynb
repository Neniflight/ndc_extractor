{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code gets the keyword frequencies and topics mentioned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv(\"../Output/20240419_CN_NDC_sentences_qc.csv\")\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = pd.read_csv(\"../Data/keywords_for_marine_policy.csv\")\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_keywords = ([stemmer.stem(keyword) for keyword in keywords_df[\"Keyword\"]])\n",
    "keywords = list(keywords_df['Keyword'])\n",
    "keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stemmed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_topics = {}\n",
    "for index in keywords_df.index:\n",
    "    if not keyword_topics.get(keywords_df.loc[index, \"Keyword\"]):\n",
    "        keyword_topics[keywords_df.loc[index, \"Keyword\"]] = [keywords_df.loc[index, \"Topic\"]]\n",
    "    else:\n",
    "        keyword_topics[keywords_df.loc[index, \"Keyword\"]].append(keywords_df.loc[index, \"Topic\"])\n",
    "keyword_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics = set(keywords_df['Topic'])\n",
    "unique_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(text, keyword_set):\n",
    "    text = text.lower()\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    text = ''.join(char for char in text if char not in punctuations)\n",
    "    \n",
    "    counts = {}\n",
    "    for index in range(len(keyword_set)):\n",
    "        counts[keywords[index]] = text.count(keyword_set[index])\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_counts = cleaned_data.apply(lambda row: count_keywords(row['text_content'], stemmed_keywords), axis=1, result_type='expand')\n",
    "cleaned_data = pd.concat([cleaned_data, keyword_counts], axis=1)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_topic(text, topics):\n",
    "    text = text.lower()\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    text = ''.join(char for char in text if char not in punctuations)\n",
    "\n",
    "    topic_counts_local = {topic: 0 for topic in topics}\n",
    "    for index in range(len(stemmed_keywords)):\n",
    "        freq = text.count(stemmed_keywords[index])\n",
    "        for topic in keyword_topics[keywords[index]]:\n",
    "            topic_counts_local[topic] += freq\n",
    "    return topic_counts_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keyword_counts = cleaned_data.loc[:, 'text_content'].apply(lambda x: count_topic(x, unique_topics)).apply(pd.Series)\n",
    "cleaned_data = pd.concat([cleaned_data, topic_keyword_counts], axis=1)\n",
    "cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(\"../Output/topic_keyword_freq_NDC_sentences_CN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
